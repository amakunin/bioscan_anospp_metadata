{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import itertools\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import ete3\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] test\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "# logging.getLogger().setFormat('[%(levelname)s] %(message)s')\n",
    "\n",
    "def setup_logging(verbose=False):\n",
    "    try: \n",
    "        del logging.root.handlers[:]\n",
    "    except:\n",
    "        pass\n",
    "    if verbose:\n",
    "        logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')\n",
    "    else:\n",
    "        logging.basicConfig(level=logging.WARNING, format='[%(levelname)s] %(message)s')\n",
    "setup_logging(verbose=True)   \n",
    "logging.info('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'data/NE BIOSCAN_Manifest_V1.0_Yarner_2021.xlsx'\n",
    "template_fn = '../data/BIOSCAN_Manifest_V1.0_20211207.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and install taxonomy\n",
    "ncbi = ete3.NCBITaxa()\n",
    "# only run update if needed\n",
    "# ncbi.update_taxonomy_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] reading data from 'data/NE BIOSCAN_Manifest_V1.0_Yarner_2021.xlsx'\n",
      "[WARNING] trailing spaces found in column 'WHAT_3_WORDS', SERIES [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184]. Removing for validation\n",
      "[WARNING] trailing spaces found in column 'ORDER', SERIES [88, 343, 344, 345, 650, 756, 757, 758, 759, 760, 833, 861, 905, 906, 907, 908, 936]. Removing for validation\n"
     ]
    }
   ],
   "source": [
    "def get_data(fn):\n",
    "\n",
    "    logging.info('reading data from {!r}'.format(fn))\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(fn, dtype=str, index_col=0, keep_default_na=False,\n",
    "                           sheet_name='TAB1 Specimen Metadata Entry')\n",
    "    except:\n",
    "        df = pd.read_excel(fn, dtype=str, index_col=0, keep_default_na=False,\n",
    "                           sheet_name='Specimen Metadata Entry')\n",
    "    \n",
    "    if df.index.duplicated().any():\n",
    "        logging.error('duplicate SERIES: {}'.format(df.index[df.index.duplicated()].to_list()))\n",
    "        \n",
    "    # trailing spaces\n",
    "    for col in df.columns:\n",
    "        trailing_spaces = (df[col].str.startswith(' ') | df[col].str.endswith(' '))\n",
    "        if trailing_spaces.any():\n",
    "            logging.warning('trailing spaces found in column {!r}, SERIES {}. Removing for validation'.format(col,\n",
    "                df.loc[trailing_spaces].index.to_list()))\n",
    "            df[col] = df[col].str.strip()\n",
    "        \n",
    "    return df\n",
    "df = get_data(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] reading data from '../data/BIOSCAN_Manifest_V1.0_20211207.xlsx'\n"
     ]
    }
   ],
   "source": [
    "template_df = get_data(template_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] checking manifest columns against template\n"
     ]
    }
   ],
   "source": [
    "def check_columns(df, template_df):\n",
    "    \n",
    "    logging.info('checking manifest columns against template')\n",
    "    \n",
    "    data_cols = set(df.columns)\n",
    "    template_cols = set(template_df.columns)\n",
    "        \n",
    "    if data_cols - template_cols != set():\n",
    "        logging.warning('extra columns in filled manifest compared to template: {}'.format(data_cols - template_cols))\n",
    "    if template_cols - data_cols != set():\n",
    "        logging.error('template columns missing from filled manifest: {}'.format(template_cols - data_cols))\n",
    "check_columns(df, template_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] extracting value validation data from '../data/BIOSCAN_Manifest_V1.0_20211207.xlsx'\n"
     ]
    }
   ],
   "source": [
    "def get_valid_dict(fn):\n",
    "    \n",
    "    # pick up validation values from data validation sheet\n",
    "    logging.info('extracting value validation data from {!r}'.format(fn))\n",
    "    valid_df = pd.read_excel(fn, dtype=str, sheet_name='Data Validation - do not edit')\n",
    "    valid_dict = dict()\n",
    "    for col in valid_df.columns:\n",
    "        valid_dict[col] = valid_df[col].dropna().to_list()\n",
    "    \n",
    "    return valid_dict\n",
    "valid_dict = get_valid_dict(template_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] excluding 290 ['NOT_COLLECTED', ''] samples without data in 'TIME_OF_COLLECTION'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SERIES\n",
       "example-small               11:22:00\n",
       "example-large               11:22:00\n",
       "example-handcaught          13:00:00\n",
       "1                           11:00:00\n",
       "2                           11:00:00\n",
       "                           ...      \n",
       "1002                        10:30:00\n",
       "1003                        10:30:00\n",
       "1004                        10:30:00\n",
       "1005                        10:30:00\n",
       "1056                  NOT_APPLICABLE\n",
       "Name: TIME_OF_COLLECTION, Length: 1009, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exclude_missing(series, na_values=[]):\n",
    "    \n",
    "    # valid missing data \n",
    "    no_data = (series.isin(na_values))\n",
    "    if no_data.sum() > 0:\n",
    "        logging.info('excluding {} {!r} samples without data in {!r}'.format(no_data.sum(), na_values, series.name))\n",
    "    return series[~no_data]\n",
    "    \n",
    "exclude_missing(df['TIME_OF_COLLECTION'], na_values=['NOT_COLLECTED',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] validating SERIES\n",
      "[ERROR] Found and excluded non-numeric SERIES: ['example-small', 'example-large', 'example-handcaught']\n"
     ]
    }
   ],
   "source": [
    "def validate_series(df):\n",
    "    \n",
    "    # series should be 1,2, ..., nsamples\n",
    "    logging.info('validating SERIES')\n",
    "    \n",
    "    # exclude non-numeric SERIES\n",
    "    series_numeric = df.index.astype(str).str.isnumeric()\n",
    "    if not series_numeric.all():\n",
    "        logging.error(f'Found and excluded non-numeric SERIES: {df.index[~series_numeric].to_list()}')\n",
    "        df = df.loc[series_numeric]\n",
    "        \n",
    "    # check the remaining SERIES are continuous\n",
    "    expected_series = set([str(i) for i in range(1, df.shape[0] + 1)])\n",
    "    observed_series = set(df.index.astype(str))\n",
    "    if expected_series != observed_series:\n",
    "        logging.error(f'In SERIES, {sorted(list(expected_series - observed_series))} are missing, '\n",
    "                      f'{sorted(list(observed_series - expected_series))} are unexpected')\n",
    "        \n",
    "    return df\n",
    "        \n",
    "df = validate_series(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] validating RACK_OR_PLATE_ID and TUBE_OR_WELL_ID\n",
      "[ERROR] Found and excluded 240 empty rows based on RACK_OR_PLATE_ID and TUBE_OR_WELL_ID\n",
      "[INFO] found 1056 samples across 11 plates\n"
     ]
    }
   ],
   "source": [
    "def validate_plates_wells(df, plate_col, well_col):\n",
    "    \n",
    "    # expect only complete 96-well plates\n",
    "    logging.info(f'validating {plate_col} and {well_col}')\n",
    "    \n",
    "    empty_rows = (df[plate_col] == '') & (df[well_col] == '')\n",
    "    \n",
    "    if empty_rows.any():\n",
    "        logging.error(f'Found and excluded {empty_rows.sum()} empty rows based on {plate_col} and {well_col}')\n",
    "        df = df.loc[~empty_rows]\n",
    "    \n",
    "    logging.info(f'found {df.shape[0]} samples across {df[plate_col].nunique()} plates')\n",
    "    \n",
    "    # add 96-well plate well IDs to validation\n",
    "    row_id = list('ABCDEFGH')\n",
    "    col_id = range(1,13)\n",
    "    expected_wells = set([r + str(c) for (r,c) in itertools.product(row_id, col_id)])\n",
    "    \n",
    "    for plate, pdf in df.groupby(plate_col):\n",
    "        dup_wells =  pdf[well_col].duplicated()\n",
    "        if dup_wells.any():\n",
    "            logging.error(f'duplicate {well_col} for plate {plate}: {pdf.loc[dup_wells, well_col].unique()}')\n",
    "        observed_wells = set(pdf[well_col])\n",
    "        if observed_wells != expected_wells:\n",
    "            logging.error(f'in {well_col} for plate {plate}, wells {expected_wells - observed_wells} '\n",
    "                          f'are missing, wells {observed_wells - expected_wells} are excessive')\n",
    "    \n",
    "    return df\n",
    "        \n",
    "df = validate_plates_wells(df, 'RACK_OR_PLATE_ID', 'TUBE_OR_WELL_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Checking and excluding blank samples\n",
      "[ERROR] last well H12 is not blank at SERIES [96]: in SCIENTIFIC_NAME, expected \"blank sample\", found ['NOT_APPLICABLE']\n",
      "[INFO] found 10 blank samples based on SCIENTIFIC_NAME\n"
     ]
    }
   ],
   "source": [
    "## TODO - which columns require NA, do not remove blanks to be able to get taxids for all\n",
    "def check_blanks(df):\n",
    "    \n",
    "    logging.info('Checking and excluding blank samples')\n",
    "    \n",
    "    # last well of plate expected to be blank\n",
    "    last_well = df[df['TUBE_OR_WELL_ID'] == 'H12']\n",
    "    last_well_blanks = (last_well['SCIENTIFIC_NAME'] == 'blank sample')\n",
    "    if not last_well_blanks.all():\n",
    "        logging.error('last well H12 is not blank at SERIES {}: in SCIENTIFIC_NAME, '\n",
    "                      'expected \"blank sample\", found {}'.format(\n",
    "                        last_well[~last_well_blanks].index.to_list(),\n",
    "                        last_well[~last_well_blanks].SCIENTIFIC_NAME.to_list()\n",
    "        ))\n",
    "    \n",
    "    is_blank = (df['SCIENTIFIC_NAME'] == 'blank sample')\n",
    "    blank_df = df[is_blank]\n",
    "    \n",
    "    logging.info('found {} blank samples based on SCIENTIFIC_NAME'.format(blank_df.shape[0]))\n",
    "    \n",
    "    # check organism part\n",
    "    organism_part_pass = (blank_df['ORGANISM_PART'] == 'BLANK_SAMPLE')\n",
    "    if not organism_part_pass.all():\n",
    "        logging.error('for blanks, ORGANISM_PART expected to be BLANK_SAMPLE, found {}'.format(\n",
    "                set(blank_df.loc[~organism_part_pass, 'ORGANISM_PART'])))\n",
    "    \n",
    "    # check that NOT_APPLICABLE is filled in all applicable \"orange\" columns\n",
    "    blanks_na = blank_df[[\n",
    "        'CATCH_LOT','BOTTLE_DIRECTION','HAZARD_GROUP',\n",
    "        'REGULATORY_COMPLIANCE','DATE_OF_COLLECTION','COLLECTION_LOCATION',\n",
    "        'DECIMAL_LATITUDE','DECIMAL_LONGITUDE','WHAT_3_WORDS' # ORDER FAMILY GENUS\n",
    "    ]]\n",
    "    na_filled = (blanks_na == 'NOT_APPLICABLE').all(axis=0)\n",
    "    if not na_filled.all():\n",
    "        logging.warning('for blanks, NOT_APPLICABLE expected, but not found in columns {}'.format(\n",
    "                            na_filled[~na_filled].index.to_list()))\n",
    "    # exclude blanks from downstream analysis    \n",
    "    # logging.info('{} samples of {} left for downstream analysis'.format(df_flt.shape[0], df.shape[0]))\n",
    "    \n",
    "    return df[~is_blank]\n",
    "        \n",
    "df = check_blanks(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] validating values in column 'ORGANISM_PART'\n",
      "[ERROR] invalid values in 'ORGANISM_PART': {''}\n"
     ]
    }
   ],
   "source": [
    "def validate_values(col, df, valid_dict, sep=None, na_values=[], level='e'):\n",
    "    \n",
    "    logging.info('validating values in column {!r}'.format(col))\n",
    "    \n",
    "    if col not in df.columns:\n",
    "        logging.error('{!r} column not found in manifest'.format(col))\n",
    "        return\n",
    "    if col not in valid_dict.keys():\n",
    "        logging.error('{!r} column not found in validation sheet'.format(col))\n",
    "        return\n",
    "    assert level in ('i','w','e'), '{!r} invalid logging level for validate_values'.format(level)\n",
    "    \n",
    "    series = df[col]\n",
    "    series = exclude_missing(series, na_values)\n",
    "    \n",
    "    col_values = set(series.unique())\n",
    "    # use separator to split values\n",
    "    if sep:\n",
    "        sep_col_values = list()\n",
    "        for v in col_values:\n",
    "            sep_col_values.extend([x.strip() for x in v.split(sep)])\n",
    "        col_values = set(sep_col_values)\n",
    "    valid_values = set(valid_dict[col])\n",
    "    invalid_values = col_values - valid_values\n",
    "    if len(invalid_values) > 0:\n",
    "        msg = 'invalid values in {!r}: {}'.format(col, invalid_values)\n",
    "        if level == 'i':\n",
    "            logging.info(msg)\n",
    "        elif level == 'w':\n",
    "            logging.warning(msg)\n",
    "        elif level == 'e':\n",
    "            logging.error(msg)\n",
    "#     else:\n",
    "#         logging.info('all values valid in {!r}'.format(col))\n",
    "            \n",
    "validate_values('ORGANISM_PART', df, valid_dict, sep=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] validating date column 'DATE_OF_COLLECTION'\n",
      "[ERROR] invalid dates in 'DATE_OF_COLLECTION': ['NOT_COLLECTED' 'NOT_APPLICABLE' '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SERIES\n",
       "2      2021-06-26\n",
       "3      2021-06-26\n",
       "4      2021-06-26\n",
       "5      2021-06-26\n",
       "6      2021-06-26\n",
       "          ...    \n",
       "1001   2021-12-05\n",
       "1002   2021-12-05\n",
       "1003   2021-12-05\n",
       "1004   2021-12-05\n",
       "1005   2021-12-05\n",
       "Name: DATE_OF_COLLECTION, Length: 993, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_date(col, df, na_values=[]):\n",
    "    \n",
    "    logging.info('validating date column {!r}'.format(col))\n",
    "\n",
    "    if col not in df.columns:\n",
    "        logging.error('{!r} column not found in manifest'.format(col))\n",
    "        return\n",
    "    series = df[col]\n",
    "    series = exclude_missing(series, na_values)\n",
    "    \n",
    "    # invalid date formats\n",
    "    # empty string converted to NaT\n",
    "    date_series = pd.to_datetime(series, format='%Y-%m-%d', errors='coerce')\n",
    "    if date_series.isna().any():\n",
    "        logging.error('invalid dates in {!r}: {}'.format(col, \n",
    "                                                         series[date_series.isna()].unique()))\n",
    "    valid_date_series = date_series[~date_series.isna()]\n",
    "    \n",
    "    # dates in future\n",
    "    future_dates = (valid_date_series > datetime.datetime.today())\n",
    "    if future_dates.any():\n",
    "        logging.error('future dates in {!r}: {}'.format(col,\n",
    "            valid_date_series[future_dates].to_list()))\n",
    "        \n",
    "    # dates too old\n",
    "    old_dates = (valid_date_series < datetime.datetime.strptime('1900-01-01', '%Y-%m-%d'))\n",
    "    if old_dates.any():\n",
    "        logging.error(\"pre-1900 dates in {!r}: {}\".format(col,\n",
    "            valid_date_series[old_dates].to_list())) \n",
    "    \n",
    "    return valid_date_series\n",
    "df.loc[1,'DATE_OF_COLLECTION'] = 'NOT_COLLECTED'\n",
    "validate_date('DATE_OF_COLLECTION', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] validating time column 'TIME_OF_COLLECTION'\n",
      "[ERROR] invalid times in 'TIME_OF_COLLECTION': ['NOT_APPLICABLE' '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SERIES\n",
       "1      1900-01-01 11:00:00\n",
       "2      1900-01-01 11:00:00\n",
       "3      1900-01-01 11:00:00\n",
       "4      1900-01-01 11:00:00\n",
       "5      1900-01-01 11:00:00\n",
       "               ...        \n",
       "1001   1900-01-01 10:30:00\n",
       "1002   1900-01-01 10:30:00\n",
       "1003   1900-01-01 10:30:00\n",
       "1004   1900-01-01 10:30:00\n",
       "1005   1900-01-01 10:30:00\n",
       "Name: TIME_OF_COLLECTION, Length: 994, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_time(col, df, na_values=[]):\n",
    "    \n",
    "    logging.info('validating time column {!r}'.format(col))\n",
    "    \n",
    "    if col not in df.columns:\n",
    "        logging.error('{!r} column not found in manifest'.format(col))\n",
    "        return\n",
    "    series = df[col]\n",
    "    series = exclude_missing(series, na_values)\n",
    "        \n",
    "    # invalid time formats\n",
    "    # NB empty string converted to NaT\n",
    "    time_series = pd.to_datetime(series, format='%H:%M:%S', errors='coerce')\n",
    "    if time_series.isna().any():\n",
    "        logging.error('invalid times in {!r}: {}'.format(col, \n",
    "                                                         series[time_series.isna()].unique()))\n",
    "    valid_time_series = time_series[~time_series.isna()]\n",
    "    \n",
    "    return valid_time_series\n",
    "# df.loc[1,'TIME_OF_COLLECTION'] = '23'\n",
    "validate_time('TIME_OF_COLLECTION', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] validating time period column 'DURATION_OF_COLLECTION'\n",
      "[ERROR] invalid times in 'DURATION_OF_COLLECTION': ['NOT_APPLICABLE' '']\n"
     ]
    }
   ],
   "source": [
    "def validate_time_period(col, df, na_values=[]):\n",
    "    \n",
    "    logging.info('validating time period column {!r}'.format(col))\n",
    "    \n",
    "    if col not in df.columns:\n",
    "        logging.error('{!r} column not found in manifest'.format(col))\n",
    "        return\n",
    "    series = df[col]\n",
    "    series = exclude_missing(series, na_values)\n",
    "\n",
    "    # conversion with modifications for proper parsing \n",
    "    # by pd.Timedelta (does not accept missing data, e.g. 'PT1H')\n",
    "    # note - will not work for weeks and months\n",
    "    def convert_iso_duration(s):\n",
    "        if s == np.nan:\n",
    "            return np.nan\n",
    "        if not s.startswith('P') or 'T' not in s:\n",
    "            return np.nan\n",
    "        # add days\n",
    "        if s.startswith('PT'):\n",
    "            s = s.replace('PT','P0DT')\n",
    "        # add trailing minutes and seconds\n",
    "        if s.endswith('H'):\n",
    "            s += '0M0S'\n",
    "        elif s.endswith('M'):\n",
    "            s += '0S'\n",
    "        try:\n",
    "            return pd.Timedelta(s)\n",
    "        except:\n",
    "            return np.nan\n",
    "    time_period_series = series.apply(convert_iso_duration)\n",
    "    if time_period_series.isna().any():\n",
    "        logging.error('invalid times in {!r}: {}'.format(col, \n",
    "            series[time_period_series.isna()].unique()))\n",
    "    valid_time_period_series = time_period_series[~time_period_series.isna()]\n",
    "    return valid_time_period_series\n",
    "\n",
    "# df.loc[1,'DURATION_OF_COLLECTION'] = 'PVT1H'\n",
    "validate_time_period('DURATION_OF_COLLECTION', df);\n",
    "# df['DURATION_OF_COLLECTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] validating country with coordinates\n",
      "[ERROR] no partner location found for coordinates '52.0236, 0.2389'\n",
      "[ERROR] no partner location found for coordinates '51.917197, -1.148376'\n",
      "[ERROR] multiple partner countries for coordinates 'NOT_APPLICABLE, NOT_APPLICABLE': ['UNITED KINGDOM' 'NOT_APPLICABLE']skipping coordinate validation\n",
      "[ERROR] multiple partner countries for coordinates '50.598618, -3.7209498': ['UNITED KINGDOM' '']skipping coordinate validation\n",
      "[WARNING] could not locate country for coordinates ', ', partner country ''\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLLECTION_LOCATION</th>\n",
       "      <th>DECIMAL_LATITUDE</th>\n",
       "      <th>DECIMAL_LONGITUDE</th>\n",
       "      <th>coord</th>\n",
       "      <th>partner_country</th>\n",
       "      <th>coord_country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERIES</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNITED KINGDOM | ENGLAND | DEVON | EAST DARTMO...</td>\n",
       "      <td>50.592446</td>\n",
       "      <td>-3.727224</td>\n",
       "      <td>50.592446, -3.727224</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNITED KINGDOM | ENGLAND | DEVON | EAST DARTMO...</td>\n",
       "      <td>50.592446</td>\n",
       "      <td>-3.727224</td>\n",
       "      <td>50.592446, -3.727224</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNITED KINGDOM | ENGLAND | DEVON | EAST DARTMO...</td>\n",
       "      <td>50.592446</td>\n",
       "      <td>-3.727224</td>\n",
       "      <td>50.592446, -3.727224</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNITED KINGDOM | ENGLAND | DEVON | EAST DARTMO...</td>\n",
       "      <td>50.592446</td>\n",
       "      <td>-3.727224</td>\n",
       "      <td>50.592446, -3.727224</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UNITED KINGDOM | ENGLAND | DEVON | EAST DARTMO...</td>\n",
       "      <td>50.592446</td>\n",
       "      <td>-3.727224</td>\n",
       "      <td>50.592446, -3.727224</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1046 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      COLLECTION_LOCATION DECIMAL_LATITUDE  \\\n",
       "SERIES                                                                       \n",
       "1       UNITED KINGDOM | ENGLAND | DEVON | EAST DARTMO...        50.592446   \n",
       "2       UNITED KINGDOM | ENGLAND | DEVON | EAST DARTMO...        50.592446   \n",
       "3       UNITED KINGDOM | ENGLAND | DEVON | EAST DARTMO...        50.592446   \n",
       "4       UNITED KINGDOM | ENGLAND | DEVON | EAST DARTMO...        50.592446   \n",
       "5       UNITED KINGDOM | ENGLAND | DEVON | EAST DARTMO...        50.592446   \n",
       "...                                                   ...              ...   \n",
       "1051                                                                         \n",
       "1052                                                                         \n",
       "1053                                                                         \n",
       "1054                                                                         \n",
       "1055                                                                         \n",
       "\n",
       "       DECIMAL_LONGITUDE                 coord partner_country   coord_country  \n",
       "SERIES                                                                          \n",
       "1              -3.727224  50.592446, -3.727224  UNITED KINGDOM  UNITED KINGDOM  \n",
       "2              -3.727224  50.592446, -3.727224  UNITED KINGDOM  UNITED KINGDOM  \n",
       "3              -3.727224  50.592446, -3.727224  UNITED KINGDOM  UNITED KINGDOM  \n",
       "4              -3.727224  50.592446, -3.727224  UNITED KINGDOM  UNITED KINGDOM  \n",
       "5              -3.727224  50.592446, -3.727224  UNITED KINGDOM  UNITED KINGDOM  \n",
       "...                  ...                   ...             ...             ...  \n",
       "1051                                        ,                          UNKNOWN  \n",
       "1052                                        ,                          UNKNOWN  \n",
       "1053                                        ,                          UNKNOWN  \n",
       "1054                                        ,                          UNKNOWN  \n",
       "1055                                        ,                          UNKNOWN  \n",
       "\n",
       "[1046 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to be replaced/supported by w3w check\n",
    "def check_location(df, fn, na_values=[]):\n",
    "    \n",
    "    logging.info('validating country with coordinates')\n",
    "    \n",
    "    loc_col, lat_col, lon_col = 'COLLECTION_LOCATION', 'DECIMAL_LATITUDE', 'DECIMAL_LONGITUDE'\n",
    "\n",
    "    try:\n",
    "        loc_df_complete = df[[loc_col, lat_col, lon_col]].copy()\n",
    "    except:\n",
    "        logging.error('One of {!r} {!r} {!r} columns not found in manifest'.format(loc_col, lat_col, lon_col))\n",
    "        return\n",
    "    loc_df_isna = (loc_df_complete.isin(na_values)).all(axis=1)\n",
    "    if loc_df_isna.any():\n",
    "        logging.info('removing {} {!r} samples with missing data from coordinate analysis'.format(\n",
    "                loc_df_isna.sum(), na_values))\n",
    "    loc_df_complete = loc_df_complete[~loc_df_isna].copy()\n",
    "    \n",
    "    # coordinates in geopy format\n",
    "    loc_df_complete['coord'] = loc_df_complete.apply(lambda x: '{}, {}'.format(\n",
    "            x[lat_col], x[lon_col]), axis=1)\n",
    "    \n",
    "    # get location data for coordinates\n",
    "    # use local copy of web query results for re-runs\n",
    "    # this \n",
    "    loc_fn = fn+'_loc.pkl'\n",
    "    if os.path.isfile(loc_fn):\n",
    "        locations = pickle.load(open(loc_fn, \"rb\"))\n",
    "    else:\n",
    "        # web map server - openstreetmaps\n",
    "        logging.info('querying coordinates')\n",
    "        locator = Nominatim(user_agent='myGeocoder')\n",
    "        rgeocode = RateLimiter(locator.reverse, min_delay_seconds=1)\n",
    "\n",
    "        locations = dict()\n",
    "        for c in loc_df_complete.coord.unique():\n",
    "            # pre-fill with unknown country\n",
    "            locations[c] = {'address':{'country':'UNKNOWN'}}\n",
    "            # check coordniate correctness\n",
    "            try:\n",
    "                lat, lon = c.split(', ')\n",
    "                lat, lon = float(lat), float(lon)\n",
    "            except:\n",
    "                logging.error('problem parsing coordinates {!r}'.format(c))\n",
    "                continue\n",
    "            if abs(lat) > 90:\n",
    "                logging.error('invalid latitude {}, should be in [-90,90]'.format(lat))\n",
    "                continue\n",
    "            if abs(lon) > 180:\n",
    "                logging.error('invalid longitude {}, should be in [-180,180]'.format(lon))\n",
    "                continue\n",
    "            # web query\n",
    "            location = rgeocode(c, language='en-gb')\n",
    "            # rgeocode returns empty location outside of counries and in some other situations\n",
    "            if location is not None:\n",
    "                locations[c] = location.raw\n",
    "\n",
    "        # save locations to file\n",
    "        pickle.dump(locations, open(loc_fn, \"wb\"))\n",
    "        \n",
    "    # parse country from partner input\n",
    "    loc_df_complete['partner_country'] = loc_df_complete[loc_col].apply(lambda x: x.split('|')[0].strip().upper())\n",
    "    \n",
    "    # extract countries from location data\n",
    "    loc_countries = dict()\n",
    "    for coord in locations.keys():\n",
    "        coord_country = locations[coord]['address']['country'].upper()\n",
    "        loc_countries[coord] = coord_country\n",
    "        \n",
    "        partner_countries = loc_df_complete.loc[loc_df_complete.coord == coord, 'partner_country']\n",
    "        if partner_countries.nunique() > 1:\n",
    "            logging.error('multiple partner countries for coordinates {!r}: {}'\n",
    "                          'skipping coordinate validation'.format(\n",
    "                                coord, partner_countries.unique()))\n",
    "            continue\n",
    "        if partner_countries.shape[0] == 0:\n",
    "            logging.error('no partner location found for coordinates {!r}'.format(coord))\n",
    "            continue\n",
    "        partner_country = partner_countries.iloc[0]\n",
    "        if coord_country == 'UNKNOWN':\n",
    "            logging.warning('could not locate country for coordinates {!r}, partner country {!r}'.format(\n",
    "                    coord, partner_country))\n",
    "        elif partner_country != coord_country:\n",
    "            logging.error('country mismatch for coordinates {!r}, partner country {!r}, '\n",
    "                          'coordinate country {!r}'.format(coord, partner_country, coord_country))\n",
    "    \n",
    "    # countries based on coordinates\n",
    "    loc_df_complete['coord_country'] = loc_df_complete['coord'].replace(loc_countries)\n",
    "    country_mismatch = (loc_df_complete.coord_country != loc_df_complete.partner_country)\n",
    "\n",
    "#     if country_mismatch.any():\n",
    "#         logging.error('coordinates do not match country for SERIES: {}'.format(\n",
    "#                 country_mismatch[country_mismatch].index.to_list()))\n",
    "    \n",
    "    # location data can be re-used, e.g. as an additional field\n",
    "    return loc_df_complete\n",
    "# df.loc[2,'DECIMAL_LATITUDE'] = '65'\n",
    "loc_test = check_location(df, fn)\n",
    "loc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] validating taxonomy against NCBI\n",
      "[INFO] validating ORDER against NCBI\n",
      "[ERROR] ORDER: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] ORDER: unexpected case for \"NOT_COLLECTED\", changing to \"Not_collected\" for validation\n",
      "[ERROR] ORDER: unexpected case for \"diptera\", changing to \"Diptera\" for validation\n",
      "[ERROR] ORDER: unexpected case for \"Diptera and Arachnidae\", changing to \"Diptera and arachnidae\" for validation\n",
      "[ERROR] ORDER: {'', 'Not_collected', 'Not_applicable', 'Diptera and arachnidae', 'Acari (subclass)', 'Tricoptera', 'Symphyleona'} not found in NCBI Taxonomy\n",
      "[WARNING] ORDER: found unexpected rank for Collembola (taxid 30001): class\n",
      "[INFO] ORDER: using only first matching rank for Plecoptera (taxid 50622): order\n",
      "[WARNING] ORDER: found unexpected rank for Protura (taxid 29999): class\n",
      "[INFO] validating FAMILY against NCBI\n",
      "[ERROR] FAMILY: unexpected case for \"NOT_COLLECTED\", changing to \"Not_collected\" for validation\n",
      "[ERROR] FAMILY: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] FAMILY: unexpected case for \"Unkown and Acari\", changing to \"Unkown and acari\" for validation\n",
      "[ERROR] FAMILY: {'', 'Not_collected', 'Not_applicable', 'Unkown and acari', 'Aphidiodea'} not found in NCBI Taxonomy\n",
      "[WARNING] FAMILY: found unexpected rank for Aphidoidea (taxid 33385): superfamily\n",
      "[INFO] validating GENUS against NCBI\n",
      "[ERROR] GENUS: unexpected case for \"NOT_COLLECTED\", changing to \"Not_collected\" for validation\n",
      "[ERROR] GENUS: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] GENUS: {'', 'Not_collected', 'Not_applicable'} not found in NCBI Taxonomy\n",
      "[INFO] GENUS: using only first matching rank for Bombus (taxid 28641): genus\n",
      "[INFO] validating SCIENTIFIC_NAME against NCBI\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"NOT_COLLECTED\", changing to \"Not_collected\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: {'', 'Not_collected', 'Not_applicable'} not found in NCBI Taxonomy\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"Acari (subclass)\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"NOT_APPLICABLE\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate GENUS for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate SCIENTIFIC_NAME for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate GENUS for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"diptera\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate GENUS for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"Diptera and Arachnidae\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate GENUS for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate GENUS for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate GENUS for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[ERROR] Family Syrphidae (taxid 34680) does not belong to Hymenoptera (taxid 7399)\n",
      "[ERROR] Genus Syrphus (taxid 224255) does not belong to Hymenoptera (taxid 7399)\n",
      "[ERROR] Species Syrphus ribesii (taxid 1124549) does not belong to Hymenoptera (taxid 7399)\n",
      "[INFO] cannot validate GENUS for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"Tricoptera\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate GENUS for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"Aphidiodea\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"Tricoptera\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate GENUS for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"NOT_COLLECTED\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"Symphyleona\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"\", skipping taxonomy consistency check\n"
     ]
    }
   ],
   "source": [
    "def validate_ncbi_taxonomy(df, ncbi, na_values = []):\n",
    "    \n",
    "    logging.info('validating taxonomy against NCBI')\n",
    "    \n",
    "    tax_columns = [\n",
    "        'ORDER',\n",
    "        'FAMILY',\n",
    "        'GENUS',\n",
    "        'SCIENTIFIC_NAME'\n",
    "    ]        \n",
    "    \n",
    "    hierarchies = df[tax_columns].drop_duplicates().copy()\n",
    "    \n",
    "    tax_info = dict()\n",
    "    \n",
    "    for tax_level in tax_columns:\n",
    "        \n",
    "        logging.info(f'validating {tax_level} against NCBI')\n",
    "        \n",
    "        if tax_level not in df.columns:\n",
    "                logging.error(f'{tax_level} column not found in manifest')\n",
    "                continue\n",
    "            \n",
    "        tax_names = list(hierarchies[tax_level].unique())\n",
    "        \n",
    "        for na_value in na_values:\n",
    "            try:\n",
    "                tax_names.remove(na_value)\n",
    "            except:\n",
    "                pass \n",
    "            \n",
    "        for i, tax_name in enumerate(tax_names):\n",
    "            if len(tax_name) == 0:\n",
    "                continue\n",
    "            corr_tax_name = tax_name[0].upper() + tax_name[1:].lower()\n",
    "            if corr_tax_name != tax_name and tax_name != 'blank sample':\n",
    "                logging.error(f'{tax_level}: unexpected case for \"{tax_name}\", '\n",
    "                              f'changing to \"{corr_tax_name}\" for validation')\n",
    "            tax_names[i] = corr_tax_name\n",
    "        \n",
    "        tax_info[tax_level] = ncbi.get_name_translator(tax_names) \n",
    "        \n",
    "        unmatched_names = set(tax_names) - set(tax_info[tax_level].keys())\n",
    "        if len(unmatched_names) > 0:\n",
    "            logging.error(f'{tax_level}: {unmatched_names} not found in NCBI Taxonomy')\n",
    "        \n",
    "        expected_rank = 'species' if (tax_level == 'SCIENTIFIC_NAME') else tax_level.lower()\n",
    "        \n",
    "        for tname, tids in tax_info[tax_level].items():\n",
    "            \n",
    "            ranks = ncbi.get_rank(tids)\n",
    "            \n",
    "            upd_tid = tids[0]\n",
    "            \n",
    "            if len(tids) == 1:\n",
    "                if ranks[upd_tid] != expected_rank: \n",
    "                    # TODO warning->info for ORDER\n",
    "                    logging.warning(f'{tax_level}: found unexpected rank for {tname} (taxid {upd_tid}): {ranks[upd_tid]}')\n",
    "            if len(tids) > 1:            \n",
    "                for tid, r in ranks.items():\n",
    "                    if r == expected_rank and len(tids) > 1:\n",
    "                        logging.info(f'{tax_level}: using only first matching rank for {tname} (taxid {tid}): {r}')\n",
    "                        upd_tid = tid\n",
    "                        break\n",
    "                else:\n",
    "                    logging.warning(f'{tax_level}: could not find matching rank for {tname}, '\n",
    "                                    f'using (taxid {upd_tid}): {ranks[upd_tid]}')\n",
    "                    \n",
    "            tax_info[tax_level][tname] = upd_tid\n",
    "        \n",
    "        #logging.info(f'{tax_level} {tax_info[tax_level]}')\n",
    "                    \n",
    "    # check correctness of taxonomy\n",
    "    for _, r in hierarchies.iterrows():\n",
    "        \n",
    "        if r.ORDER in na_values:\n",
    "            continue\n",
    "        try:\n",
    "            order_id = tax_info['ORDER'][r.ORDER]\n",
    "        except KeyError:\n",
    "            logging.info(f'cannot validate ORDER for \"{r.ORDER}\", skipping taxonomy consistency check')\n",
    "            continue\n",
    "            \n",
    "        if r.FAMILY in na_values:\n",
    "            continue\n",
    "        try:\n",
    "            family_id = tax_info['FAMILY'][r.FAMILY]\n",
    "            \n",
    "            family_lineage = ncbi.get_lineage(family_id)\n",
    "            \n",
    "            if order_id not in family_lineage:\n",
    "                logging.error(f'Family {r.FAMILY} (taxid {family_id}) does not belong to {r.ORDER} (taxid {order_id})')\n",
    "        except KeyError:\n",
    "            logging.info(f'cannot validate FAMILY for \"{r.FAMILY}\", skipping taxonomy consistency check')\n",
    "            continue\n",
    "            \n",
    "        if r.GENUS in na_values:\n",
    "            continue\n",
    "        try:\n",
    "            genus_id = tax_info['GENUS'][r.GENUS]\n",
    "            \n",
    "            genus_lineage = ncbi.get_lineage(genus_id)\n",
    "            \n",
    "            if order_id not in genus_lineage:\n",
    "                logging.error(f'Genus {r.GENUS} (taxid {genus_id}) does not belong to {r.ORDER} (taxid {order_id})')\n",
    "            if family_id not in genus_lineage:\n",
    "                logging.error(f'Genus {r.GENUS} (taxid {genus_id}) does not belong to {r.FAMILY} (taxid {family_id})')\n",
    "        except KeyError:\n",
    "            logging.info(f'cannot validate GENUS for \"{r.GENUS}\", skipping taxonomy consistency check')\n",
    "            continue\n",
    "            \n",
    "        if r.SCIENTIFIC_NAME in na_values:\n",
    "            continue\n",
    "        try:\n",
    "            species_id = tax_info['SCIENTIFIC_NAME'][r.SCIENTIFIC_NAME]\n",
    "            \n",
    "            species_lineage = ncbi.get_lineage(species_id)\n",
    "            \n",
    "            if order_id not in species_lineage:\n",
    "                logging.error(f'Species {r.SCIENTIFIC_NAME} (taxid {species_id}) does not belong to {r.ORDER} (taxid {order_id})')\n",
    "            if family_id not in species_lineage:\n",
    "                logging.error(f'Species {r.SCIENTIFIC_NAME} (taxid {species_id}) does not belong to {r.FAMILY} (taxid {family_id})')\n",
    "            if genus_id not in species_lineage:\n",
    "                logging.error(f'Species {r.SCIENTIFIC_NAME} (taxid {species_id}) does not belong to {r.GENUS} (taxid {genus_id})')\n",
    "        except KeyError:\n",
    "            logging.info(f'cannot validate SCIENTIFIC_NAME for \"{r.SCIENTIFIC_NAME}\", skipping taxonomy consistency check')\n",
    "            continue\n",
    "            \n",
    "    return df\n",
    "        \n",
    "                \n",
    "validate_ncbi_taxonomy(df, ncbi);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] validating int format in TIME_ELAPSED_FROM_COLLECTION_TO_PLATING\n",
      "[ERROR] found non-integer value in TIME_ELAPSED_FROM_COLLECTION_TO_PLATING: \"NOT_APPLICABLE\"\n",
      "[ERROR] found non-integer value in TIME_ELAPSED_FROM_COLLECTION_TO_PLATING: \"\"\n"
     ]
    }
   ],
   "source": [
    "def validate_int(col, df, na_values=[]):\n",
    "    \n",
    "    logging.info(f'validating int format in {col}')\n",
    "    \n",
    "    if col not in df.columns:\n",
    "        logging.error(f'{col} column not found in manifest')\n",
    "        return\n",
    "    series = df[col]\n",
    "    series = exclude_missing(series, na_values)\n",
    "    \n",
    "    for val in series.unique():\n",
    "        try:\n",
    "            int(val)\n",
    "        except:\n",
    "            logging.error(f'found non-integer value in {col}: \"{val}\"')\n",
    "validate_int('TIME_ELAPSED_FROM_COLLECTION_TO_PLATING', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] validating date column 'DATE_OF_COLLECTION'\n",
      "[ERROR] invalid dates in 'DATE_OF_COLLECTION': ['NOT_COLLECTED' 'NOT_APPLICABLE' '']\n",
      "[INFO] validating date column 'DATE_OF_PRESERVATION'\n",
      "[ERROR] invalid dates in 'DATE_OF_PRESERVATION': ['' 'NOT_APPLICABLE']\n"
     ]
    }
   ],
   "source": [
    "bd = validate_date('DATE_OF_COLLECTION', df)\n",
    "ad = validate_date('DATE_OF_PRESERVATION', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctdf = pd.concat([bd, ad], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "6       False\n",
       "        ...  \n",
       "1001    False\n",
       "1002    False\n",
       "1003    False\n",
       "1004    False\n",
       "1005    False\n",
       "Length: 993, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctdf.iloc[:, 0] > ctdf.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dates(before, after):\n",
    "    \n",
    "    ctdf = pd.concat([before.reset_index(), after.reset_index()], axis=1)\n",
    "    date_conflict = ctdf[before.name] > ctdf[after.name]\n",
    "    \n",
    "#     logging.info(date_conflict)\n",
    "    if date_conflict.any():\n",
    "        logging.error(f'{before.name} values are later than {after.name} for SERIES'\n",
    "                      f' {ctdf[date_conflict].index.to_list()}')\n",
    "    \n",
    "compare_dates(bd, ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] # started validate_partner_manifest_v.1.0\n",
      "[WARNING] # manifest data/NE BIOSCAN_Manifest_V1.0_Yarner_2021.xlsx\n",
      "[INFO] reading data from 'data/NE BIOSCAN_Manifest_V1.0_Yarner_2021.xlsx'\n",
      "[WARNING] trailing spaces found in column 'WHAT_3_WORDS', SERIES [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184]. Removing for validation\n",
      "[WARNING] trailing spaces found in column 'ORDER', SERIES [88, 343, 344, 345, 650, 756, 757, 758, 759, 760, 833, 861, 905, 906, 907, 908, 936]. Removing for validation\n",
      "[INFO] reading data from '../data/BIOSCAN_Manifest_V1.0_20211207.xlsx'\n",
      "[INFO] checking manifest columns against template\n",
      "[INFO] extracting value validation data from '../data/BIOSCAN_Manifest_V1.0_20211207.xlsx'\n",
      "[INFO] validating SERIES\n",
      "[ERROR] Found and excluded non-numeric SERIES: ['example-small', 'example-large', 'example-handcaught']\n",
      "[INFO] validating RACK_OR_PLATE_ID and TUBE_OR_WELL_ID\n",
      "[ERROR] Found and excluded 240 empty rows based on RACK_OR_PLATE_ID and TUBE_OR_WELL_ID\n",
      "[INFO] found 1056 samples across 11 plates\n",
      "[INFO] Checking and excluding blank samples\n",
      "[ERROR] last well H12 is not blank at SERIES [96]: in SCIENTIFIC_NAME, expected \"blank sample\", found ['NOT_APPLICABLE']\n",
      "[INFO] found 10 blank samples based on SCIENTIFIC_NAME\n",
      "[INFO] validating values in column 'PRESERVATIVE_SOLUTION'\n",
      "[INFO] validating values in column 'BOTTLE_DIRECTION'\n",
      "[ERROR] invalid values in 'BOTTLE_DIRECTION': {''}\n",
      "[INFO] validating values in column 'ORGANISM_PART'\n",
      "[ERROR] invalid values in 'ORGANISM_PART': {''}\n",
      "[INFO] validating values in column 'HAZARD_GROUP'\n",
      "[ERROR] invalid values in 'HAZARD_GROUP': {'', 'NOT_APPLICABLE'}\n",
      "[INFO] validating values in column 'REGULATORY_COMPLIANCE'\n",
      "[ERROR] invalid values in 'REGULATORY_COMPLIANCE': {'', 'y'}\n",
      "[INFO] validating date column 'DATE_OF_COLLECTION'\n",
      "[ERROR] invalid dates in 'DATE_OF_COLLECTION': ['NOT_APPLICABLE' '']\n",
      "[INFO] validating country with coordinates\n",
      "[ERROR] no partner location found for coordinates '52.0236, 0.2389'\n",
      "[ERROR] no partner location found for coordinates '51.917197, -1.148376'\n",
      "[ERROR] multiple partner countries for coordinates 'NOT_APPLICABLE, NOT_APPLICABLE': ['UNITED KINGDOM' 'NOT_APPLICABLE']skipping coordinate validation\n",
      "[ERROR] multiple partner countries for coordinates '50.598618, -3.7209498': ['UNITED KINGDOM' '']skipping coordinate validation\n",
      "[WARNING] could not locate country for coordinates ', ', partner country ''\n",
      "[INFO] validating taxonomy against NCBI\n",
      "[INFO] validating ORDER against NCBI\n",
      "[ERROR] ORDER: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] ORDER: unexpected case for \"diptera\", changing to \"Diptera\" for validation\n",
      "[ERROR] ORDER: unexpected case for \"Diptera and Arachnidae\", changing to \"Diptera and arachnidae\" for validation\n",
      "[ERROR] ORDER: {'', 'Not_applicable', 'Diptera and arachnidae', 'Acari (subclass)', 'Tricoptera', 'Symphyleona'} not found in NCBI Taxonomy\n",
      "[WARNING] ORDER: found unexpected rank for Collembola (taxid 30001): class\n",
      "[INFO] ORDER: using only first matching rank for Plecoptera (taxid 50622): order\n",
      "[WARNING] ORDER: found unexpected rank for Protura (taxid 29999): class\n",
      "[INFO] validating FAMILY against NCBI\n",
      "[ERROR] FAMILY: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] FAMILY: unexpected case for \"Unkown and Acari\", changing to \"Unkown and acari\" for validation\n",
      "[ERROR] FAMILY: {'', 'Aphidiodea', 'Not_applicable', 'Unkown and acari'} not found in NCBI Taxonomy\n",
      "[WARNING] FAMILY: found unexpected rank for Aphidoidea (taxid 33385): superfamily\n",
      "[INFO] validating GENUS against NCBI\n",
      "[ERROR] GENUS: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] GENUS: {'', 'Not_applicable'} not found in NCBI Taxonomy\n",
      "[INFO] GENUS: using only first matching rank for Bombus (taxid 28641): genus\n",
      "[INFO] validating SCIENTIFIC_NAME against NCBI\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: {'', 'Not_applicable'} not found in NCBI Taxonomy\n",
      "[INFO] cannot validate ORDER for \"Acari (subclass)\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"NOT_APPLICABLE\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"diptera\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"Diptera and Arachnidae\", skipping taxonomy consistency check\n",
      "[ERROR] Family Syrphidae (taxid 34680) does not belong to Hymenoptera (taxid 7399)\n",
      "[ERROR] Genus Syrphus (taxid 224255) does not belong to Hymenoptera (taxid 7399)\n",
      "[ERROR] Species Syrphus ribesii (taxid 1124549) does not belong to Hymenoptera (taxid 7399)\n",
      "[INFO] cannot validate ORDER for \"Tricoptera\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate FAMILY for \"Aphidiodea\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"Tricoptera\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"Symphyleona\", skipping taxonomy consistency check\n",
      "[INFO] cannot validate ORDER for \"\", skipping taxonomy consistency check\n",
      "[INFO] validating values in column 'SEX'\n",
      "[ERROR] invalid values in 'SEX': {''}\n",
      "[INFO] validating time column 'TIME_OF_COLLECTION'\n",
      "[ERROR] invalid times in 'TIME_OF_COLLECTION': ['NOT_APPLICABLE' '']\n",
      "[INFO] validating time period column 'DURATION_OF_COLLECTION'\n",
      "[ERROR] invalid times in 'DURATION_OF_COLLECTION': ['NOT_APPLICABLE' '']\n",
      "[INFO] validating values in column 'COLLECTION_METHOD'\n",
      "[ERROR] invalid values in 'COLLECTION_METHOD': {''}\n",
      "[INFO] validating int format in TIME_ELAPSED_FROM_COLLECTION_TO_PLATING\n",
      "[INFO] excluding 50 [''] samples without data in 'TIME_ELAPSED_FROM_COLLECTION_TO_PLATING'\n",
      "[ERROR] found non-integer value in TIME_ELAPSED_FROM_COLLECTION_TO_PLATING: \"NOT_APPLICABLE\"\n",
      "[INFO] validating date column 'DATE_OF_PRESERVATION'\n",
      "[INFO] excluding 1044 [''] samples without data in 'DATE_OF_PRESERVATION'\n",
      "[ERROR] invalid dates in 'DATE_OF_PRESERVATION': ['NOT_APPLICABLE']\n",
      "[INFO] validating int format in ELEVATION\n",
      "[INFO] excluding 1046 [''] samples without data in 'ELEVATION'\n",
      "[INFO] # ended validate_partner_manifest_v.1.0\n"
     ]
    }
   ],
   "source": [
    "def validate(fn, template_fn, verbose=False, version='1.0'):\n",
    "    '''\n",
    "    Validation follows the order of columns order in data entry sheet\n",
    "    '''\n",
    "\n",
    "    setup_logging(verbose=verbose)\n",
    "\n",
    "    logging.info(f'# started validate_partner_manifest_v.{version}')\n",
    "    logging.warning(f'# manifest {fn}')\n",
    "\n",
    "    # read data\n",
    "    df = get_data(fn)\n",
    "    \n",
    "    # read taxonomy\n",
    "    ncbi = ete3.NCBITaxa()\n",
    "    \n",
    "    # prepare for validation\n",
    "    template_df = get_data(template_fn)\n",
    "    check_columns(df, template_df)\n",
    "    valid_dict = get_valid_dict(template_fn)\n",
    "\n",
    "    # orange cols\n",
    "    df = validate_series(df)\n",
    "    df = validate_plates_wells(df, 'RACK_OR_PLATE_ID', 'TUBE_OR_WELL_ID')\n",
    "    \n",
    "    # check blanks\n",
    "    df = check_blanks(df)\n",
    "    \n",
    "    validate_values('PRESERVATIVE_SOLUTION', df, valid_dict)\n",
    "    # CATCH_LOT not checked TODO do not allow missing\n",
    "    validate_values('BOTTLE_DIRECTION', df, valid_dict)\n",
    "    validate_values('ORGANISM_PART', df, valid_dict, sep='|')\n",
    "    validate_values('HAZARD_GROUP', df, valid_dict)\n",
    "    validate_values('REGULATORY_COMPLIANCE', df, valid_dict)\n",
    "    date_coll = validate_date('DATE_OF_COLLECTION', df, na_values=['NOT_COLLECTED'])\n",
    "    check_location(df, fn)\n",
    "    \n",
    "    # purple cols\n",
    "    # taxonomy validation adds a few columns\n",
    "    df = validate_ncbi_taxonomy(df, ncbi, na_values = ['NOT_COLLECTED'])\n",
    "    validate_values('SEX', df, valid_dict)\n",
    "    # HABITAT not checked\n",
    "    validate_time('TIME_OF_COLLECTION', df)\n",
    "    validate_time_period('DURATION_OF_COLLECTION', df, na_values=['NOT_COLLECTED'])\n",
    "    validate_values('COLLECTION_METHOD', df, valid_dict)\n",
    "    # DESCRIPTION_OF_COLLECTION_METHOD not checked\n",
    "    validate_int('TIME_ELAPSED_FROM_COLLECTION_TO_PLATING', df, na_values=[''])\n",
    "    # PHOTOGRAPH_* columns not checked\n",
    "    # VOUCHER_ID not checked\n",
    "    # PRESERVATION_APPROACH not checked - should match DATE_OF_PRESERVATION\n",
    "    date_pres = validate_date('DATE_OF_PRESERVATION', df, na_values=['']) # allow for empty values unlike DATE_OF_COLLECTION\n",
    "    compare_dates(before=date_coll, after=date_pres)\n",
    "    # COLLECTOR_SAMPLE_ID not checked\n",
    "    validate_int('ELEVATION', df, na_values=[''])\n",
    "    # OTHER_INFORMATION\tMISC_METADATA\tIDENTIFIED_BY\tIDENTIFIER_AFFILIATION\tIDENTIFIED_HOW not checked\n",
    "        \n",
    "    logging.info('# ended validate_partner_manifest_v.{}'.format(version))\n",
    "\n",
    "    return df\n",
    "\n",
    "# fn = '../../results/partner_manifests/IRD-Neandersquito_T222Amplicon_Manifest_V2.0.xlsx'\n",
    "df = validate(fn, template_fn, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real manifests validation starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] # manifest ../results/August 2021 Manifest (Bill _ Fred).xlsx\n",
      "[ERROR] duplicate SERIES: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 'SERIES', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "[WARNING] trailing spaces found in column 'DURATION_OF_COLLECTION', SERIES [43]. Removing for validation\n",
      "[ERROR] Found and excluded non-numeric SERIES: ['SERIES', 'SERIES', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "[ERROR] In SERIES, ['100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '97', '98', '99'] are missing, ['904', '905', '906', '907', '908', '909', '910', '911', '912', '913', '914', '915', '916', '917', '918', '919', '920', '921', '922', '923', '924', '925', '926', '927', '928', '929', '930', '931', '932', '933', '934', '935', '936', '937', '938', '939', '940', '941', '942', '943', '944', '945', '946', '947', '948', '949', '950', '951', '952', '953', '954', '955', '956', '957', '958', '959', '960'] are unexpected\n",
      "[ERROR] Found and excluded 615 empty rows based on RACK_OR_PLATE_ID and TUBE_OR_WELL_ID\n",
      "[ERROR] for blanks, ORGANISM_PART expected to be BLANK_SAMPLE, found {'NOT_APPLICABLE'}\n",
      "[ERROR] invalid values in 'ORGANISM_PART': {'Leg'}\n",
      "[WARNING] could not locate country for coordinates '51.164794, -5.6578888', partner country 'UNITED KINGDOM'\n",
      "[ERROR] ORDER: {'Arachnid'} not found in NCBI Taxonomy\n",
      "[WARNING] ORDER: found unexpected rank for Arachnida (taxid 6854): class\n",
      "[WARNING] ORDER: found unexpected rank for Collembola (taxid 30001): class\n",
      "[ERROR] invalid times in 'DURATION_OF_COLLECTION': ['']\n",
      "[ERROR] found non-integer value in TIME_ELAPSED_FROM_COLLECTION_TO_PLATING: \"3H\"\n",
      "[ERROR] found non-integer value in TIME_ELAPSED_FROM_COLLECTION_TO_PLATING: \"3h\"\n"
     ]
    }
   ],
   "source": [
    "df = validate('../results/August 2021 Manifest (Bill _ Fred).xlsx', template_fn, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] # manifest ../results/Mike Ashworth NE 2021-05-28 corrected BIOSCAN_Manifest_V1.0.xlsx\n",
      "[ERROR] Found and excluded non-numeric SERIES: ['example-small', 'example-large', 'example-handcaught']\n",
      "[ERROR] Found and excluded 672 empty rows based on RACK_OR_PLATE_ID and TUBE_OR_WELL_ID\n",
      "[WARNING] GENUS: found unexpected rank for Scathophaga stercoraria (taxid 95463): species\n"
     ]
    }
   ],
   "source": [
    "df = validate('../results/Mike Ashworth NE 2021-05-28 corrected BIOSCAN_Manifest_V1.0.xlsx', template_fn, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] # manifest ../results/Mike Ashworth NE 2021-06-24 BIOSCAN_Manifest_V1.0.xlsx\n",
      "[ERROR] Found and excluded 672 empty rows based on RACK_OR_PLATE_ID and TUBE_OR_WELL_ID\n"
     ]
    }
   ],
   "source": [
    "df = validate('../results/Mike Ashworth NE 2021-06-24 BIOSCAN_Manifest_V1.0.xlsx', template_fn, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] # manifest ../results/NE BIOSCAN_Manifest_V1.0_Yarner_260621.xlsx\n",
      "[WARNING] trailing spaces found in column 'WHAT_3_WORDS', SERIES [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184]. Removing for validation\n",
      "[WARNING] trailing spaces found in column 'ORDER', SERIES [88]. Removing for validation\n",
      "[ERROR] Found and excluded non-numeric SERIES: ['example-small', 'example-large', 'example-handcaught']\n",
      "[ERROR] Found and excluded 768 empty rows based on RACK_OR_PLATE_ID and TUBE_OR_WELL_ID\n",
      "[ERROR] duplicate TUBE_OR_WELL_ID for plate MOZZ00000924A: ['']\n",
      "[ERROR] in TUBE_OR_WELL_ID for plate MOZZ00000924A, wells {'F12', 'D12', 'A12', 'G12', 'C12', 'E12', 'B12'} are missing, wells {''} are excessive\n",
      "[ERROR] last well H12 is not blank at SERIES [96]: in SCIENTIFIC_NAME, expected \"blank sample\", found ['NOT_APPLICABLE']\n",
      "[ERROR] invalid values in 'PRESERVATIVE_SOLUTION': {''}\n",
      "[ERROR] invalid values in 'BOTTLE_DIRECTION': {''}\n",
      "[ERROR] invalid values in 'ORGANISM_PART': {''}\n",
      "[ERROR] invalid values in 'HAZARD_GROUP': {'', 'NOT_APPLICABLE'}\n",
      "[ERROR] invalid values in 'REGULATORY_COMPLIANCE': {''}\n",
      "[ERROR] invalid dates in 'DATE_OF_COLLECTION': ['NOT_APPLICABLE' '']\n",
      "[WARNING] could not locate country for coordinates 'NOT_APPLICABLE, NOT_APPLICABLE', partner country 'UNITED KINGDOM'\n",
      "[WARNING] could not locate country for coordinates ', ', partner country ''\n",
      "[ERROR] ORDER: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] ORDER: {'', 'Acari (subclass)', 'Not_applicable'} not found in NCBI Taxonomy\n",
      "[WARNING] ORDER: found unexpected rank for Collembola (taxid 30001): class\n",
      "[ERROR] FAMILY: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] FAMILY: {'', 'Not_applicable'} not found in NCBI Taxonomy\n",
      "[ERROR] GENUS: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] GENUS: {'', 'Not_applicable'} not found in NCBI Taxonomy\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: {'', 'Not_applicable'} not found in NCBI Taxonomy\n",
      "[ERROR] invalid values in 'SEX': {''}\n",
      "[ERROR] invalid times in 'TIME_OF_COLLECTION': ['NOT_APPLICABLE' '']\n",
      "[ERROR] invalid times in 'DURATION_OF_COLLECTION': ['NOT_APPLICABLE' '']\n",
      "[ERROR] invalid values in 'COLLECTION_METHOD': {''}\n",
      "[ERROR] found non-integer value in TIME_ELAPSED_FROM_COLLECTION_TO_PLATING: \"NOT_APPLICABLE\"\n",
      "[ERROR] invalid dates in 'DATE_OF_PRESERVATION': ['NOT_APPLICABLE']\n"
     ]
    }
   ],
   "source": [
    "df = validate('../results/NE BIOSCAN_Manifest_V1.0_Yarner_260621.xlsx', template_fn, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] # manifest ../results/NatureScot Working Copy_ of BIOSCAN_Manifest_V1.0 (A3484399).xlsx\n",
      "[WARNING] trailing spaces found in column 'ORDER', SERIES [593, 595, 598, 628, 1103]. Removing for validation\n",
      "[WARNING] trailing spaces found in column 'FAMILY', SERIES [1052]. Removing for validation\n",
      "[WARNING] trailing spaces found in column 'OTHER_INFORMATION', SERIES [1194, 1195, 1196, 1197, 1198]. Removing for validation\n",
      "[WARNING] trailing spaces found in column 'IDENTIFIED_BY', SERIES [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959]. Removing for validation\n",
      "[ERROR] Found and excluded non-numeric SERIES: ['example-small', 'example-large', 'example-handcaught-large', 'example-handcaught-small']\n",
      "[ERROR] last well H12 is not blank at SERIES [1248]: in SCIENTIFIC_NAME, expected \"blank sample\", found ['']\n",
      "[ERROR] invalid values in 'PRESERVATIVE_SOLUTION': {''}\n",
      "[ERROR] invalid values in 'BOTTLE_DIRECTION': {'', 'n'}\n",
      "[ERROR] invalid values in 'ORGANISM_PART': {'', 'WHOLE_ORGANISm', 'whOLE_ORGANISM', 'WHOLE_ORG', 'Whole organism', 'WhOLE_ORGANISM', 'WhoLE_ORGANISM'}\n",
      "[ERROR] invalid values in 'HAZARD_GROUP': {''}\n",
      "[ERROR] invalid values in 'REGULATORY_COMPLIANCE': {''}\n",
      "[ERROR] invalid dates in 'DATE_OF_COLLECTION': ['']\n",
      "[WARNING] could not locate country for coordinates '-3.844011, 57.186786', partner country 'UNITED KINGDOM'\n",
      "[WARNING] could not locate country for coordinates ', ', partner country ''\n",
      "[ERROR] ORDER: unexpected case for \"LEPIDOPTERA\", changing to \"Lepidoptera\" for validation\n",
      "[ERROR] ORDER: {'', 'Aranae'} not found in NCBI Taxonomy\n",
      "[WARNING] ORDER: found unexpected rank for Collembola (taxid 30001): class\n",
      "[ERROR] FAMILY: unexpected case for \"vespidae\", changing to \"Vespidae\" for validation\n",
      "[ERROR] FAMILY: {'', 'Aphidae', 'Tentredinidae', 'Formicdae', 'Apidea', 'Canthaidae'} not found in NCBI Taxonomy\n",
      "[WARNING] FAMILY: found unexpected rank for Ichneumon (taxid 27520): genus\n",
      "[WARNING] FAMILY: found unexpected rank for Limoniinae (taxid 52737): subfamily\n",
      "[ERROR] GENUS: unexpected case for \"prizoma\", changing to \"Prizoma\" for validation\n",
      "[ERROR] GENUS: {'', 'Prizoma', 'Dzidzickia'} not found in NCBI Taxonomy\n",
      "[ERROR] SCIENTIFIC_NAME: {'', 'Vespa vulgaris', 'Lycophotia porphyreya'} not found in NCBI Taxonomy\n",
      "[ERROR] Family Syrphidae (taxid 34680) does not belong to Hemiptera (taxid 7524)\n",
      "[ERROR] invalid values in 'SEX': {''}\n",
      "[ERROR] invalid times in 'TIME_OF_COLLECTION': ['0.46875' '']\n",
      "[ERROR] invalid times in 'DURATION_OF_COLLECTION': ['']\n",
      "[ERROR] invalid values in 'COLLECTION_METHOD': {''}\n",
      "[ERROR] found non-integer value in TIME_ELAPSED_FROM_COLLECTION_TO_PLATING: \"1.5\"\n"
     ]
    }
   ],
   "source": [
    "df = validate('../results/NatureScot Working Copy_ of BIOSCAN_Manifest_V1.0 (A3484399).xlsx', template_fn, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] # manifest ../results/Shap 2021-05-28 corrected.xlsx\n",
      "[ERROR] Found and excluded non-numeric SERIES: ['example-small', 'example-large', 'example-handcaught']\n",
      "[ERROR] Found and excluded 768 empty rows based on RACK_OR_PLATE_ID and TUBE_OR_WELL_ID\n",
      "[WARNING] for blanks, NOT_APPLICABLE expected, but not found in columns ['CATCH_LOT', 'BOTTLE_DIRECTION', 'WHAT_3_WORDS']\n",
      "[ERROR] invalid values in 'ORGANISM_PART': {'Head'}\n",
      "[WARNING] ORDER: found unexpected rank for Collembola (taxid 30001): class\n",
      "[ERROR] FAMILY: {''} not found in NCBI Taxonomy\n",
      "[ERROR] GENUS: {''} not found in NCBI Taxonomy\n",
      "[ERROR] SCIENTIFIC_NAME: {''} not found in NCBI Taxonomy\n",
      "[ERROR] invalid values in 'SEX': {''}\n",
      "[ERROR] invalid times in 'TIME_OF_COLLECTION': ['11.52' '11.5']\n",
      "[ERROR] invalid dates in 'DATE_OF_PRESERVATION': ['NOT_APPLICABLE']\n"
     ]
    }
   ],
   "source": [
    "df = validate('../results/Shap 2021-05-28 corrected.xlsx', template_fn, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] # manifest ../results/Bioscan metadata_Jan_22_WYTHAM_WOODS.xlsx\n",
      "[WARNING] trailing spaces found in column 'ORDER', SERIES [385, 388, 397, 399, 400, 401, 405, 409, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 448, 449, 453, 454, 455, 457, 460, 462, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 479]. Removing for validation\n",
      "[WARNING] trailing spaces found in column 'FAMILY', SERIES [385, 1898]. Removing for validation\n",
      "[WARNING] trailing spaces found in column 'GENUS', SERIES [133, 205, 385, 386, 1059, 1654]. Removing for validation\n",
      "[ERROR] In SERIES, ['1000', '1001', '1002', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '1014', '1015', '1016', '1017', '1018', '1019', '1020', '1021', '1022', '1023', '1024', '1025', '1026', '1027', '1028', '1029', '1030', '1031', '1032', '1033', '1034', '1035', '1036', '1037', '1038', '1039', '1040', '1041', '1042', '1043', '1044', '1045', '1046', '1047', '1048', '1049', '1050', '1051', '1052', '1053', '1054', '1055', '1056', '1153', '1154', '1155', '1156', '1157', '1158', '1159', '1160', '1161', '1162', '1163', '1164', '1165', '1166', '1167', '1168', '1169', '1170', '1171', '1172', '1173', '1174', '1175', '1176', '1177', '1178', '1179', '1180', '1181', '1182', '1183', '1184', '1185', '1186', '1187', '1188', '1189', '1190', '1191', '1192', '1193', '1194', '1195', '1196', '1197', '1198', '1199', '1200', '1201', '1202', '1203', '1204', '1205', '1206', '1207', '1208', '1209', '1210', '1211', '1212', '1213', '1214', '1215', '1216', '1217', '1218', '1219', '1220', '1221', '1222', '1223', '1224', '1225', '1226', '1227', '1228', '1229', '1230', '1231', '1232', '1233', '1234', '1235', '1236', '1237', '1238', '1239', '1240', '1241', '1242', '1243', '1244', '1245', '1246', '1247', '1248', '1249', '1250', '1251', '1252', '1253', '1254', '1255', '1256', '1257', '1258', '1259', '1260', '1261', '1262', '1263', '1264', '1265', '1266', '1267', '1268', '1269', '1270', '1271', '1272', '1273', '1274', '1275', '1276', '1277', '1278', '1279', '1280', '1281', '1282', '1283', '1284', '1285', '1286', '1287', '1288', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721', '722', '723', '724', '725', '726', '727', '728', '729', '730', '731', '732', '733', '734', '735', '736', '737', '738', '739', '740', '741', '742', '743', '744', '745', '746', '747', '748', '749', '750', '751', '752', '753', '754', '755', '756', '757', '758', '759', '760', '761', '762', '763', '764', '765', '766', '767', '768', '769', '770', '771', '772', '773', '774', '775', '776', '777', '778', '779', '780', '781', '782', '783', '784', '785', '786', '787', '788', '789', '790', '791', '792', '793', '794', '795', '796', '797', '798', '799', '800', '801', '802', '803', '804', '805', '806', '807', '808', '809', '810', '811', '812', '813', '814', '815', '816', '817', '818', '819', '820', '821', '822', '823', '824', '825', '826', '827', '828', '829', '830', '831', '832', '833', '834', '835', '836', '837', '838', '839', '840', '841', '842', '843', '844', '845', '846', '847', '848', '849', '850', '851', '852', '853', '854', '855', '856', '857', '858', '859', '860', '861', '862', '863', '864', '865', '866', '867', '868', '869', '870', '871', '872', '873', '874', '875', '876', '877', '878', '879', '880', '881', '882', '883', '884', '885', '886', '887', '888', '889', '890', '891', '892', '893', '894', '895', '896', '897', '898', '899', '900', '901', '902', '903', '904', '905', '906', '907', '908', '909', '910', '911', '912', '913', '914', '915', '916', '917', '918', '919', '920', '921', '922', '923', '924', '925', '926', '927', '928', '929', '930', '931', '932', '933', '934', '935', '936', '937', '938', '939', '940', '941', '942', '943', '944', '945', '946', '947', '948', '949', '950', '951', '952', '953', '954', '955', '956', '957', '958', '959', '960', '961', '962', '963', '964', '965', '966', '967', '968', '969', '970', '971', '972', '973', '974', '975', '976', '977', '978', '979', '980', '981', '982', '983', '984', '985', '986', '987', '988', '989', '990', '991', '992', '993', '994', '995', '996', '997', '998', '999'] are missing, ['1345', '1346', '1347', '1348', '1349', '1350', '1351', '1352', '1353', '1354', '1355', '1356', '1357', '1358', '1359', '1360', '1361', '1362', '1363', '1364', '1365', '1366', '1367', '1368', '1369', '1370', '1371', '1372', '1373', '1374', '1375', '1376', '1377', '1378', '1379', '1380', '1381', '1382', '1383', '1384', '1385', '1386', '1387', '1388', '1389', '1390', '1391', '1392', '1393', '1394', '1395', '1396', '1397', '1398', '1399', '1400', '1401', '1402', '1403', '1404', '1405', '1406', '1407', '1408', '1409', '1410', '1411', '1412', '1413', '1414', '1415', '1416', '1417', '1418', '1419', '1420', '1421', '1422', '1423', '1424', '1425', '1426', '1427', '1428', '1429', '1430', '1431', '1432', '1433', '1434', '1435', '1436', '1437', '1438', '1439', '1440', '1441', '1442', '1443', '1444', '1445', '1446', '1447', '1448', '1449', '1450', '1451', '1452', '1453', '1454', '1455', '1456', '1457', '1458', '1459', '1460', '1461', '1462', '1463', '1464', '1465', '1466', '1467', '1468', '1469', '1470', '1471', '1472', '1473', '1474', '1475', '1476', '1477', '1478', '1479', '1480', '1481', '1482', '1483', '1484', '1485', '1486', '1487', '1488', '1489', '1490', '1491', '1492', '1493', '1494', '1495', '1496', '1497', '1498', '1499', '1500', '1501', '1502', '1503', '1504', '1505', '1506', '1507', '1508', '1509', '1510', '1511', '1512', '1513', '1514', '1515', '1516', '1517', '1518', '1519', '1520', '1521', '1522', '1523', '1524', '1525', '1526', '1527', '1528', '1529', '1530', '1531', '1532', '1533', '1534', '1535', '1536', '1537', '1538', '1539', '1540', '1541', '1542', '1543', '1544', '1545', '1546', '1547', '1548', '1549', '1550', '1551', '1552', '1553', '1554', '1555', '1556', '1557', '1558', '1559', '1560', '1561', '1562', '1563', '1564', '1565', '1566', '1567', '1568', '1569', '1570', '1571', '1572', '1573', '1574', '1575', '1576', '1577', '1578', '1579', '1580', '1581', '1582', '1583', '1584', '1585', '1586', '1587', '1588', '1589', '1590', '1591', '1592', '1593', '1594', '1595', '1596', '1597', '1598', '1599', '1600', '1601', '1602', '1603', '1604', '1605', '1606', '1607', '1608', '1609', '1610', '1611', '1612', '1613', '1614', '1615', '1616', '1617', '1618', '1619', '1620', '1621', '1622', '1623', '1624', '1625', '1626', '1627', '1628', '1629', '1630', '1631', '1632', '1633', '1634', '1635', '1636', '1637', '1638', '1639', '1640', '1641', '1642', '1643', '1644', '1645', '1646', '1647', '1648', '1649', '1650', '1651', '1652', '1653', '1654', '1655', '1656', '1657', '1658', '1659', '1660', '1661', '1662', '1663', '1664', '1665', '1666', '1667', '1668', '1669', '1670', '1671', '1672', '1673', '1674', '1675', '1676', '1677', '1678', '1679', '1680', '1681', '1682', '1683', '1684', '1685', '1686', '1687', '1688', '1689', '1690', '1691', '1692', '1693', '1694', '1695', '1696', '1697', '1698', '1699', '1700', '1701', '1702', '1703', '1704', '1705', '1706', '1707', '1708', '1709', '1710', '1711', '1712', '1713', '1714', '1715', '1716', '1717', '1718', '1719', '1720', '1721', '1722', '1723', '1724', '1725', '1726', '1727', '1728', '1729', '1730', '1731', '1732', '1733', '1734', '1735', '1736', '1737', '1738', '1739', '1740', '1741', '1742', '1743', '1744', '1745', '1746', '1747', '1748', '1749', '1750', '1751', '1752', '1753', '1754', '1755', '1756', '1757', '1758', '1759', '1760', '1761', '1762', '1763', '1764', '1765', '1766', '1767', '1768', '1769', '1770', '1771', '1772', '1773', '1774', '1775', '1776', '1777', '1778', '1779', '1780', '1781', '1782', '1783', '1784', '1785', '1786', '1787', '1788', '1789', '1790', '1791', '1792', '1793', '1794', '1795', '1796', '1797', '1798', '1799', '1800', '1801', '1802', '1803', '1804', '1805', '1806', '1807', '1808', '1809', '1810', '1811', '1812', '1813', '1814', '1815', '1816', '1817', '1818', '1819', '1820', '1821', '1822', '1823', '1824', '1825', '1826', '1827', '1828', '1829', '1830', '1831', '1832', '1833', '1834', '1835', '1836', '1837', '1838', '1839', '1840', '1841', '1842', '1843', '1844', '1845', '1846', '1847', '1848', '1849', '1850', '1851', '1852', '1853', '1854', '1855', '1856', '1857', '1858', '1859', '1860', '1861', '1862', '1863', '1864', '1865', '1866', '1867', '1868', '1869', '1870', '1871', '1872', '1873', '1874', '1875', '1876', '1877', '1878', '1879', '1880', '1881', '1882', '1883', '1884', '1885', '1886', '1887', '1888', '1889', '1890', '1891', '1892', '1893', '1894', '1895', '1896', '1897', '1898', '1899', '1900', '1901', '1902', '1903', '1904', '1905', '1906', '1907', '1908', '1909', '1910', '1911', '1912', '1913', '1914', '1915', '1916', '1917', '1918', '1919', '1920', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025', '2026', '2027', '2028', '2029', '2030', '2031', '2032', '2033', '2034', '2035', '2036', '2037', '2038', '2039', '2040', '2041', '2042', '2043', '2044', '2045', '2046', '2047', '2048', '2049', '2050', '2051', '2052', '2053', '2054', '2055', '2056'] are unexpected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] Found and excluded 40 empty rows based on RACK_OR_PLATE_ID and TUBE_OR_WELL_ID\n",
      "[ERROR] last well H12 is not blank at SERIES [96, 192, 288, 384, 480, 576, 1152, 1440, 1536, 1632, 1728, 1824, 1920]: in SCIENTIFIC_NAME, expected \"blank sample\", found ['', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "[ERROR] invalid values in 'PRESERVATIVE_SOLUTION': {'', 'Ethanol'}\n",
      "[ERROR] invalid values in 'BOTTLE_DIRECTION': {'', 'South', 'North'}\n",
      "[ERROR] invalid values in 'ORGANISM_PART': {'', 'Leg', 'Whole', 'Antenna', 'Abdomen'}\n",
      "[ERROR] invalid values in 'HAZARD_GROUP': {''}\n",
      "[ERROR] invalid values in 'REGULATORY_COMPLIANCE': {''}\n",
      "[ERROR] invalid dates in 'DATE_OF_COLLECTION': ['' '23/06/0201']\n",
      "[ERROR] country mismatch for coordinates '51.7717, -1.3333', partner country 'GRASSLAND', coordinate country 'UNITED KINGDOM'\n",
      "[ERROR] country mismatch for coordinates '51.7736, -1.3383', partner country 'WOODLAND', coordinate country 'UNITED KINGDOM'\n",
      "[WARNING] could not locate country for coordinates ', ', partner country ''\n",
      "[ERROR] country mismatch for coordinates '51.7736000000001, -1.3383', partner country 'WOODLAND', coordinate country 'UNITED KINGDOM'\n",
      "[ERROR] country mismatch for coordinates '51.7736000000002, -1.3383', partner country 'WOODLAND', coordinate country 'UNITED KINGDOM'\n",
      "[ERROR] multiple partner countries for coordinates '51.7736000000002, -1.33829999999999': ['WOODLAND' 'WOODS']skipping coordinate validation\n",
      "[ERROR] country mismatch for coordinates '51.7736000000003, -1.33829999999999', partner country 'WOODLAND', coordinate country 'UNITED KINGDOM'\n",
      "[ERROR] ORDER: unexpected case for \"lepidoptera\", changing to \"Lepidoptera\" for validation\n",
      "[ERROR] ORDER: {'', 'Hermetera', 'Hymenotera', '?'} not found in NCBI Taxonomy\n",
      "[WARNING] ORDER: found unexpected rank for Collembola (taxid 30001): class\n",
      "[ERROR] FAMILY: unexpected case for \"wasp reduced venation on wing compared to flies\", changing to \"Wasp reduced venation on wing compared to flies\" for validation\n",
      "[ERROR] FAMILY: unexpected case for \"two triangles on the wing formed by veins\", changing to \"Two triangles on the wing formed by veins\" for validation\n",
      "[ERROR] FAMILY: unexpected case for \"possible parasite attached\", changing to \"Possible parasite attached\" for validation\n",
      "[ERROR] FAMILY: unexpected case for \"formicidae\", changing to \"Formicidae\" for validation\n",
      "[ERROR] FAMILY: {'', 'Aphidae', 'Psychididae', 'Phoridae?', 'Possible parasite attached', 'Miridae?', 'Wasp reduced venation on wing compared to flies', 'Simulidae', 'Two triangles on the wing formed by veins', 'Muscidae?', 'Aphydidae', 'Empidae'} not found in NCBI Taxonomy\n",
      "[WARNING] FAMILY: found unexpected rank for Aphidoidea (taxid 33385): superfamily\n",
      "[WARNING] FAMILY: found unexpected rank for Chironomoidea (taxid 41828): superfamily\n",
      "[WARNING] FAMILY: found unexpected rank for Nematocera (taxid 7148): suborder\n",
      "[WARNING] FAMILY: found unexpected rank for Tenthredinoidea (taxid 85772): superfamily\n",
      "[WARNING] FAMILY: found unexpected rank for Vespula (taxid 7451): genus\n",
      "[ERROR] GENUS: unexpected case for \"(Alticini)\", changing to \"(alticini)\" for validation\n",
      "[ERROR] GENUS: unexpected case for \"(Belytinae)\", changing to \"(belytinae)\" for validation\n",
      "[ERROR] GENUS: {'', '(alticini)', 'Vulgaris', '(belytinae)'} not found in NCBI Taxonomy\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"lucorum sensu lato\", changing to \"Lucorum sensu lato\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"pascuorum\", changing to \"Pascuorum\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"major\", changing to \"Major\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"eLegans\", changing to \"Elegans\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"aucupariae\", changing to \"Aucupariae\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"heraclei\", changing to \"Heraclei\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"terrestris\", changing to \"Terrestris\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: {'', 'Brachypalpoides lentus\\n', 'Heraclei', 'Elegans', 'Pascuorum', 'Lucorum sensu lato', 'Terrestris', 'Aucupariae'} not found in NCBI Taxonomy\n",
      "[WARNING] SCIENTIFIC_NAME: found unexpected rank for Major (taxid 1925465): genus\n",
      "[ERROR] invalid values in 'SEX': {'', 'Male', 'F', 'Female', 'female'}\n",
      "[ERROR] invalid times in 'TIME_OF_COLLECTION': ['']\n",
      "[ERROR] invalid times in 'DURATION_OF_COLLECTION': ['']\n",
      "[ERROR] invalid values in 'COLLECTION_METHOD': {''}\n"
     ]
    }
   ],
   "source": [
    "df = validate('../results/Bioscan metadata_Jan_22_WYTHAM_WOODS.xlsx', template_fn, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] # manifest ../results/NE BIOSCAN_Manifest_V1.0_Yarner_2021.xlsx\n",
      "[WARNING] trailing spaces found in column 'WHAT_3_WORDS', SERIES [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184]. Removing for validation\n",
      "[WARNING] trailing spaces found in column 'ORDER', SERIES [88, 343, 344, 345, 650, 756, 757, 758, 759, 760, 833, 861, 905, 906, 907, 908, 936]. Removing for validation\n",
      "[ERROR] last well H12 is not blank at SERIES [96]: in SCIENTIFIC_NAME, expected \"blank sample\", found ['NOT_APPLICABLE']\n",
      "[ERROR] invalid values in 'BOTTLE_DIRECTION': {''}\n",
      "[ERROR] invalid values in 'ORGANISM_PART': {''}\n",
      "[ERROR] invalid values in 'HAZARD_GROUP': {'', 'NOT_APPLICABLE'}\n",
      "[ERROR] invalid values in 'REGULATORY_COMPLIANCE': {'', 'y'}\n",
      "[ERROR] invalid dates in 'DATE_OF_COLLECTION': ['NOT_APPLICABLE' '']\n",
      "[ERROR] multiple partner countries for coordinates 'NOT_APPLICABLE, NOT_APPLICABLE': ['UNITED KINGDOM' 'NOT_APPLICABLE']skipping coordinate validation\n",
      "[ERROR] multiple partner countries for coordinates '50.598618, -3.7209498': ['UNITED KINGDOM' '']skipping coordinate validation\n",
      "[WARNING] could not locate country for coordinates ', ', partner country ''\n",
      "[ERROR] ORDER: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] ORDER: unexpected case for \"diptera\", changing to \"Diptera\" for validation\n",
      "[ERROR] ORDER: unexpected case for \"Diptera and Arachnidae\", changing to \"Diptera and arachnidae\" for validation\n",
      "[ERROR] ORDER: {'', 'Not_applicable', 'Diptera and arachnidae', 'Acari (subclass)', 'Tricoptera', 'Symphyleona'} not found in NCBI Taxonomy\n",
      "[WARNING] ORDER: found unexpected rank for Collembola (taxid 30001): class\n",
      "[WARNING] ORDER: found unexpected rank for Protura (taxid 29999): class\n",
      "[ERROR] FAMILY: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] FAMILY: unexpected case for \"Unkown and Acari\", changing to \"Unkown and acari\" for validation\n",
      "[ERROR] FAMILY: {'', 'Aphidiodea', 'Not_applicable', 'Unkown and acari'} not found in NCBI Taxonomy\n",
      "[WARNING] FAMILY: found unexpected rank for Aphidoidea (taxid 33385): superfamily\n",
      "[ERROR] GENUS: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] GENUS: {'', 'Not_applicable'} not found in NCBI Taxonomy\n",
      "[ERROR] SCIENTIFIC_NAME: unexpected case for \"NOT_APPLICABLE\", changing to \"Not_applicable\" for validation\n",
      "[ERROR] SCIENTIFIC_NAME: {'', 'Not_applicable'} not found in NCBI Taxonomy\n",
      "[ERROR] Family Syrphidae (taxid 34680) does not belong to Hymenoptera (taxid 7399)\n",
      "[ERROR] Genus Syrphus (taxid 224255) does not belong to Hymenoptera (taxid 7399)\n",
      "[ERROR] Species Syrphus ribesii (taxid 1124549) does not belong to Hymenoptera (taxid 7399)\n",
      "[ERROR] invalid values in 'SEX': {''}\n",
      "[ERROR] invalid times in 'TIME_OF_COLLECTION': ['NOT_APPLICABLE' '']\n",
      "[ERROR] invalid times in 'DURATION_OF_COLLECTION': ['NOT_APPLICABLE' '']\n",
      "[ERROR] invalid values in 'COLLECTION_METHOD': {''}\n",
      "[ERROR] found non-integer value in TIME_ELAPSED_FROM_COLLECTION_TO_PLATING: \"NOT_APPLICABLE\"\n",
      "[ERROR] invalid dates in 'DATE_OF_PRESERVATION': ['NOT_APPLICABLE']\n"
     ]
    }
   ],
   "source": [
    "df = validate('../results/NE BIOSCAN_Manifest_V1.0_Yarner_2021.xlsx', template_fn, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
